---
title: "Problem Set"
author: "Prof. Bisbee"
institute: "Yonsei University"
date: "Due Date: 2022/08/25 @ 9AM KST"
output:
  html_document: default
  pdf_document: default
---

## Getting Set Up

If you haven't already, create a folder for this course, and then a subfolder within for the second lecture `Topic6_UnivariateVisualization`, and two additional subfolders within `code` and `data`.

Open `RStudio` and create a new RMarkDown file (`.Rmd`) by going to `File -> New File -> R Markdown...`.
Change the title to `"DS1000: Problem Set 4"` and the author to your full name. Save this file as `[LAST NAME]_ps4.Rmd` to your `code` folder.

If you haven't already, download the `Pres2020_PV.Rds` file from the course [github page](https://github.com/jbisbee1/DSCI1000/blob/main/Lectures/Topic6_UnivariateVisualization/data/Pres2020_PV.Rds) and save it to your `data` folder.

All of the following questions should be answered using 
````{verbatim}
```{r}
# EXAMPLE CODE
mean(c(1,2,3))
```
````

## Question 1
Require `tidyverse` and load the `Pres2020_PV.Rds` data to `pres`.
```{r}
require(tidyverse)

pres <- readRDS('Pres2020_PV.Rds')
```


## Question 2
Which polling company fielded the most polls in the data?
```{r}
pres %>%
group_by(Poll) %>%
count() %>%
arrange(-n)
```
> - Morning Consult fielded the most polls in the data with 44.

## Question 3
Plot the total number of polls per start date in the data. NB: you will have convert `StartDate` to a `date` class with `as.Date()`. If you need help, see [this post](https://www.r-bloggers.com/2013/08/date-formats-in-r/).
```{r}
pres %>%
  mutate(StartDate = as.Date(StartDate,'%m/%d/%Y')) %>%
  ggplot(aes(x = StartDate)) + 
  geom_bar() + 
  labs(title = 'Total Polls Started by Day',
       x = 'Start Date',
       y = 'Number of Polls')
```


## Question 4
On average, how long were these polls in the field? Plot the distribution of this variable.
```{r}
pres %>%
  ggplot(aes(x = DaysinField)) + 
  geom_bar() + 
  labs(title = 'Duration of Polls',
       x = 'Number of Days in the Field',
       y = 'Number of Polls')
```

> - On average, polls were in the field roughly 4.48 days.

## Question 5
Which was the most common mode of interview? Simplify the `Mode` variable to either "Online", "Live Phone", or "Hybrid". Plot this result with a bar plot where the mode of interview is on the **y-axis**, not the x-axis.
```{r}
pres %>%
  filter(!is.na(Mode)) %>%
  mutate(Mode = ifelse(grepl('Live phone',Mode),'Live Phone',
                       ifelse(Mode == 'Online','Online','Hybrid'))) %>%
  ggplot(aes(y = Mode)) + 
  geom_bar() + 
  labs(title = 'Mode of Interview',
       subtitle = '"Hybrid" refers to a combination of online, live phone, and IVR',
       x = 'Number of Polls',
       y = 'Mode of Interview')
```


## Question 6
Which specific poll had the lowest margin of error (`MoE`)? Which had the highest? What about which polling organization (`Poll`)?
```{r}
# Highest Poll
pres %>%
  select(poll.id,Poll,MoE) %>%
  arrange(-MoE) %>%
  filter(!is.na(MoE))

# Lowest Poll
pres %>%
  select(poll.id,Poll,MoE) %>%
  arrange(MoE) %>%
  filter(!is.na(MoE))

# High / Low polling org
pres %>%
  group_by(Poll) %>%
  summarise(mean_moe = mean(MoE,na.rm=T)) %>%
  filter(!is.na(mean_moe)) %>%
  arrange(-mean_moe) %>%
  slice(1,nrow(.))

```

> - Poll ID #189 by Optimus had the highest margin of error (8.3). Poll ID #1936 by SurveyMonkey had the lowest margin of error (1). Overall, Optimus had the highest margin of error on average (7.78) while SurveyMOnkey had the lowest (1).

## Question 7
Plot the distribution of margin of error for individual polls using a histogram with 40 bins. Then plot the same distribution using a density plot. Which approach better describes the data? Why?
```{r}
# Histogram
pres %>%
  ggplot(aes(x = MoE)) + 
  geom_histogram(bins = 40) + 
  labs(title = 'Distribution of Poll Margin of Error',
       x = 'Margin of Error',
       y = 'Number of Polls')

# Density Plot
pres %>%
  ggplot(aes(x = MoE)) + 
  geom_density() + 
  labs(title = 'Distribution of Poll Margin of Error',
       x = 'Margin of Error',
       y = 'Density')
```

> - I argue that the histogram better describes the data because the density plot underrepresents how many polls have a margin of error of exactly 1. 

## Question 8
Calculate the average margin of error by start date and plot as a line graph. Do you observe any spikes in uncertainty? Based **only** on your read of the plot, is this a noteworthy spike?
```{r}
pres %>%
  mutate(StartDate = as.Date(StartDate,'%m/%d/%Y')) %>%
  group_by(StartDate) %>%
  summarise(MoE = mean(MoE,na.rm=T)) %>%
  ggplot(aes(x = StartDate,y = MoE)) + 
  geom_line() + 
  labs(title = 'Average Margin of Error by Start Date',
       y = 'Margin of Error',
       x = 'Start Date')
```

> I observe the largest error in the beginning of June. Based on my read of the data, this is not a noteworthy spike because it is not markedly larger than the surrounding observations. However, relative to later polls starting in mid-June, this spike is markedly larger.


## Question 8
Plot the average margin of error by start date again, but this time as a scatter plot + a smoother (`geom_smooth(se = F)`). Set the y-axis range to cover the minimum and maximum values of the margin of error in the overall data. Do you observe a noteworthy trend in the margin of error over time?
```{r}
toplot <- pres %>%
  mutate(demErr = Biden - DemCertVote,
         repErr = Trump - RepCertVote) 

pres %>%
  mutate(StartDate = as.Date(StartDate,'%m/%d/%Y')) %>%
  group_by(StartDate) %>%
  summarise(MoE = mean(MoE,na.rm=T),
            SampleSize = max(SampleSize,na.rm=T)) %>%
  ggplot(aes(x = StartDate,y = MoE)) + 
  geom_point() +
  scale_y_continuous(limits = c(min(pres$MoE,na.rm=T),max(pres$MoE,na.rm=T))) + 
  labs(title = 'Average Margin of Error by Start Date',
       y = 'Margin of Error',
       x = 'Start Date') + 
  geom_smooth(se = F)
```

> I observe a gradual decline in the margin of error over time. 

## Question 10
Calculate the **prediction error** for Biden and Trump such that positive values mean that the poll *overestimated* the candidate's popular vote share (`DemCertVote` for Biden and `RepCertVote` for Trump). Plot the Biden and Trump prediction errors on a single plot with .red[red] indicating Trump and .blue[blue] indicating Biden. Do you observe a systematic bias toward one candidate or the other? EXTRA CREDIT: Add vertical lines for the average prediction error for both candidates (colored appropriately) as well as a vertical line indicating no prediction error.

```{r}
toplot %>%
  ggplot() + 
  geom_bar(aes(x = demErr),fill = 'blue',alpha = .5) + 
  geom_bar(aes(x = repErr),fill = 'red',alpha = .5) + 
  labs(title = 'Poll Mistakes by Biden (blue) and Trump (red)',
       x = 'Prediction Error: Prediction - True Support',
       y = 'Number of Polls') + 
  theme_bw() + 
  geom_vline(xintercept = 0,lwd = 2,alpha = .3) + 
  geom_vline(xintercept = mean(toplot$demErr,na.rm=T),color = 'blue',linetype = 'dashed') + 
  geom_vline(xintercept = mean(toplot$repErr,na.rm=T),color = 'red',linetype = 'dashed')
```

> - I observe a systematic bias against both candidates where the polls underestimate the amount of support for Biden and Trump. However, the magnitude of this bias against Trump is larger than the bias against Biden. 

## Question 11
What proportion of polls underestimated Trump's support in 2020? What proportion of polls underestimated Biden's support in 2020?

```{r}
toplot %>%
  summarise(propDemErr = mean(demErr < 0),
            propRepErr = mean(repErr < 0))
```

> - 61.2% of polls underestimated Biden's popular vote share whereas 98.3% of polls underestimated Trump's popular vote share in 2020.

## Question 12
Plot the average prediction error for Trump (.red[red]) and Biden (.blue[blue]) by start date using `geom_point()` and `geom_smooth()`. Make sure to set the y-axis range to the minimum and maximum values in the overall data.

```{r}
toplot %>%
  mutate(StartDate = as.Date(StartDate,'%m/%d/%Y')) %>%
  group_by(StartDate) %>%
  summarise(demErr = mean(demErr),
            repErr = mean(repErr)) %>%
  ggplot() + 
  # geom_line(aes(x = StartDate,y = demErr),color = 'blue') + 
  # geom_line(aes(x = StartDate,y = repErr),color = 'red') + 
  geom_point(aes(x = StartDate,y = demErr),color = 'blue') +
  geom_point(aes(x = StartDate,y = repErr),color = 'red') +
  geom_smooth(aes(x = StartDate,y = demErr),color = 'blue') +
  geom_smooth(aes(x = StartDate,y = repErr),color = 'red') + 
  labs(title = "Prediction Errors for Trump (red) and Biden (blue) by Date",
       x = "Start Date",
       y = "Average Prediction Error") + 
  geom_vline(xintercept = 0,linetype = 'dashed') + 
  geom_hline(yintercept = 0,linetype = 'dashed') + 
  theme_bw() + 
  scale_y_continuous(limits = c(min(c(toplot$demErr,toplot$repErr),na.rm=T),
                                max(c(toplot$demErr,toplot$repErr),na.rm=T)))
```

## Question 13
Calculate each poll's bias toward Biden (this should be the prediction error for Biden minus the prediction error for Trump) and plot the distribution. What proportion of polls' prediction error favored Biden over Trump?

```{r}
toplot %>%
  mutate(bidenBias = demErr - repErr) %>%
  ggplot(aes(x = bidenBias)) + 
  geom_bar(alpha = .6) + 
  labs(title = '"Biden Bias" in 2020 Polls',
       subtitle = "Biden's Prediction Error minus Trump's Prediction Error",
       x = "Biden Bias: Biden's Prediction Error minus Trump's Prediction Error",
       y = 'Number of Polls') + 
  geom_vline(xintercept = 0,linetype = 'dashed') + 
  theme_bw()

toplot %>%
  mutate(bidenBias = demErr - repErr) %>%
  summarise(mean(bidenBias > 0))
```

> - 84.7% of polls had prediction errors that favored Biden over Trump.

## Question 13
EXTRA CREDIT: Do polls that underestimate Trump's support overestimate Biden's support? Use a scatterplot to test, combined with a line of best fit. Then, calculate the proportion of polls that (1) underestimate both Trump and Biden, (2) underestimate Trump and overestimate Biden, (3) overestimate Trump and underestimate Biden, (4) overestimate both candidates. In these analyses, define "overestimate" as prediction errors greater than or equal to zero, whereas "underestimate" should be prediction errors less than zero.

```{r}
toplot %>%
  ggplot(aes(x = demErr,y = repErr)) + 
  geom_point() + 
  geom_smooth(method = 'lm') + 
  labs(title = "Prediction Errors for Trump and Biden",
       x = "Biden's Prediction Error",
       y = "Trump's Prediction Error") + 
  geom_vline(xintercept = 0,linetype = 'dashed') + 
  geom_hline(yintercept = 0,linetype = 'dashed') + 
  theme_bw()

toplot %>%
  summarise(underTrumpUnderBiden = mean(demErr < 0 & repErr < 0),
            underTrumpOverBiden = mean(demErr >= 0 & repErr < 0),
            overTrumpUnderBiden = mean(demErr < 0 & repErr >= 0),
            overTrumpOverBiden = mean(demErr >= 0 & repErr >= 0))
```
